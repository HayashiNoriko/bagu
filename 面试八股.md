# Linux 系统编程

## 说一说常用的 Linux 命令

`cd` 切换目录

`cp` 拷贝当前文件或文件夹

`mv` 移动当前文件或文件夹，还可以修改文件名

`pwd` 显示当前文件或文件夹的路径 

`ls` 显示当前文件的详细信息 

`cat` 查看当前文件的内容 

`ifconfig` 获取网卡情况 

`touch` 创建文件 

`mkdir` 创建文件夹 

`rm` 删除文件或文件夹 

`kill` 查看信号 

`ps` 查看进程情况 

`tar` 对文件进行打包 

`chmod` 改变文件权限

## 静态库和动态库如何制作及使用，区别是什么

1. 静态库的制作和使用    

   - 命名规则

     Linux：`libxxx.a`

     Windows：`libxxx.lib`

   - 制作

     ```bash
     # 1.生成目标文件（只提供源代码文件列表，g++会分别生成对应的.o文件）
     g++ -c 源代码文件列表
     # 2.生成静态库
     ar rcs lib库名.a 目标文件清单
     ```

   - 使用

     ```bash
     g++ [选项] 源代码文件清单 -L 库文件所在目录 -l 库名
     ```

2. 动态库的制作和使用

   - 命名规则

     Linux：`libxxx.so`

     Windows：`libxxx.dll`     

   - 制作

     ```bash
     g++ -fPIC -shared -o lib库名.so 源代码文件清单
     ```

     或者分两步进行：`g++ -fPIC -c` 生成目标文件，`g++ -shared` 生成动态库。当某个单独的 `.o` 文件需要更新时，只更新它就可以了。

   - 使用

     ```bash
     g++ [选项] 源代码文件清单 -L 库文件所在目录 -l 库名
     ```

     在运行程序之前还需要配置动态库的加载路径，即设置 `LD_LIBRARY_PATH` 环境变量。

     - 临时设置：执行`export LD_LIBRARY_PATH = $LD_LIBRARY_PATH:库路径`
     - 永久设置：把上面这行代码设置到 `~/.bashrc` 文件中，然后执行 `source ~/.bashrc`

3. 静态库和动态库的区别

   | 静态库                                                       | 动态库                                                       |
   | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | gcc 进行链接时，会把静态库中代码打包到可执行程序中，编译时加载 | gcc 进行链接时，动态库的代码不会被打包到可执行程序中，运行时加载 |
   | 发布程序时无需提供静态库，移植方便                           | 发布程序时需要提供动态库                                     |
   | 消耗内存，更新部署发布麻烦                                   | 内存占用小，更新部署发布简单                                 |

如果动态库和静态库同时存在，编译器将优先使用动态库。

## 简述一下 GDB 常见的调试命令

| **命令**           | **简写** | **命令说明**                                                 |
| ------------------ | -------- | ------------------------------------------------------------ |
| set args           |          | 设置程序运行的参数。  例如：./demo 张三 西施 我是一只傻傻鸟  设置参数的方法是：  set args 张三 西施 我是一只傻傻鸟 |
| show args          |          | 查看设置好的运行参数                                         |
| break              | b        | 设置断点，可以设置多个断点。<br>`b 20`：表示在第 20 行设置断点<br>`b fun`：表示在函数 fun 处设置断点<br>也可以设置指定文件的断点<br>**条件断点** `b 20 if i==9`：当变量 i 为 9 时在第 20 行设置断点 |
| disable            |          | `disable n`：使设置的第 `n` 个断点无效，断点序号可以通过 `info b` 查看<br>`disable x-y`：使设置的第 x 个到第 y 个之间的断点都无效<br>`disable x y`：使设置的第 x 个和第 y 个断点无效 |
| enable             |          | 使无效的断点有效，用法同上                                   |
| delete             | d        | 删除断点，用法同上。<br>若不加任何参数，则删除全部断点       |
| info               | i        | `i b`：查看所有断点                                          |
| run                | r        | 开始运行程序，程序运行到断点的位置会停下来，如果没有遇到断点，程序一直运行下去。 可以随时使用 r 来重新运行程序。 |
| start              |          | 程序向下执行一行（初次执行时会在第一条语句处停止）           |
| next               | n        | 执行当前行语句，如果该语句为函数调用，不会进入函数内部。 (VS的F10) |
| step               | s        | 执行当前行语句，如果该语句为函数调用，则进入函数内部。(VS的F11)  注意了，如果函数是库函数或第三方提供的函数，用s也是进不去的，因为没有源代码，如果是自定义的函数，只要有源码就可以进去。 |
| finish             |          | 退出进入的函数。如果出不去，看一下函数体中是否有断点，若有则删掉或设置无效 |
| until              | u        | 退出循环体。如果出不去，看一下循环体中是否有断点，若有则删掉或设置无效 |
| print              | p        | 显示变量或表达式的值，如果p后面是表达式，会执行这个表达式。  也可以达到修改变量值的效果，和 set var 一样。 |
| ptype              |          | 显示变量的类型                                               |
| continue           | c        | 继续运行程序，遇到下一个断点停止，如果没有遇到断点，程序将一直运行。（ VS的F5） |
| display            |          | 设置每次执行调试命令后打印变量。用法和 break 类似，会存储所有要display 的变量，还使用disable display、enable display 和 delete display 控制 display 变量的状态（失效、生效、删除） |
| set var            |          | 设置变量的值。  假设程序中定义了两个变量：  int ii;   char name[21];  set var ii=10 把ii的值设置为10；  set var name="西施"。 |
| list               | l        | 查看源代码。默认显示 10 行，按回车继续显示。<br/> `list -` ：逆序查看<br/> `list n` ：查看第 `n` 行<br/> `list fun` ：查看函数 `fun` 处的代码<br/>`list filename:n`：查看文件 `filename` 的第 `n` 行代码<br/>`list filename: fun`：查看文件 `filename` 的 `fun` 函数处代码 |
| set listsize count |          | 设置一次显示源代码的行数                                     |
| show listsize      |          | 查看当前 listsize 的设置                                     |
| quit               | q        | 退出gdb。                                                    |

## 说一说进程调度算法有哪些

1. **先来先服务（FCFS）调度算法**，是一种最简单的调度算法，也称为先进先出或严格排队方案。每次调度都是从后备作业（进程）队列中选择一个或多个最先进入该队列的作业（进程），将它们调入内存，为它们分配资源、创建进程，当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。 

2. **短作业优先（SJF）调度算法**，是从后备队列中选择一个或若干个估计运行时间最短的作业（进程），将它们调入内存运行，从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或者发生某件事而阻塞时，才释放处理机。 
3. **高响应比优先调度算法**，主要用于作业调度，该算法是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。 
4. **优先级调度算法**，又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列；在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。 

5. **时间片轮转调度算法**，主要适用于分时系统。每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。 

6. **多级反馈队列调度算法**，是时间片轮转调度算法和优先级调度算法的综合和发展，通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。 

## 说一说什么是大端、小端，如何判断大端和小端

如果数据类型占用的内存空间大于 1 字节，CPU 把数据存放在内存中的方式有两种：

- 大端序（Big Endian）：低位字节存放在高位，高位字节存放在低位。

- 小端序（Little Endia）：低位字节存放在低位，高位字节存放在高位。

假设从内存地址 `0x00000001` 处开始存储十六进制数 `0x12345678`，那么：

- Big-endian（按原来顺序存储）

  | 内存地址               | 数据             |
  | ---------------------- | ---------------- |
  | 0x00000001（内存低位） | 0x12（数字高位） |
  | 0x00000002             | 0x34             |
  | 0x00000003             | 0x56             |
  | 0x00000004（内存高位） | 0x78（数字低位） |

- Little-endian（颠倒顺序储存）

  | 内存地址               | 数据             |
  | ---------------------- | ---------------- |
  | 0x00000001（内存低位） | 0x78（数字低位） |
  | 0x00000002             | 0x56             |
  | 0x00000003             | 0x34             |
  | 0x00000004（内存高位） | 0x12（数字高位） |

Intel 系列的 CPU 以小端序方式保存数据，其它型号的 CPU 不一定。

操作文件的本质是把内存中的数据写入磁盘，在网络编程中，传输数据的本质也是把数据写入文件（socket 也是文件描述符）。

这样的话，字节序不同的计算机之间传输数据，可能会出现问题。为了解决不同字节序的计算机之间传输数据的问题，约定采用网络字节序（大端序）。

## 什么是孤儿进程，什么是僵尸进程，如何解决僵尸进程

1. **孤儿进程**

   孤儿进程是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程（进程号为1）所收养，并且由 init 进程对它们完整状态收集工作，孤儿进程一般不会产生任何危害。 

2. **僵尸进程**

   僵尸进程是指一个进程使用 fork() 函数创建子进程，如果子进程退出，而父进程并没有调用 wt() 或者wtpid() 系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程。 

3. **解决僵尸进程**

   1. 捕获 `SIGCHLD`，然后忽略它
   2. 捕获 `SIGCHLD`，然后处理它：在处理函数中调用 `wait()`
   3. 直接使用使用 `wait()`，父进程将阻塞以等待子进程结束

## 说一说进程通信的方式有哪些？

1. **管道（无名 / 匿名管道）**

   它是 UNIX 系统 IPC（进程间通信）的最古老形式，所有的 UNIX 系统都支持这种通信机制。管道本质其实是内核中维护的一块内存缓冲区，Linux 系统中通过 pipe() 函数创建管道，会生成两个文件描述符，分别对应管道的读端和写端。无名管道只能用于具有亲缘关系的进程间的通信。 

2. **命名管道**

   匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道（FIFO），也叫命名管道、FIFO文件。有名管道（FIFO）不同于匿名管道之处在于它提供了一个路径名与之关联，以 FIFO 的文件形式存在于文件系统中，并且其打开方式与打开一个普通文件是一样的，这样即使与 FIFO 的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过 FIFO 相互通信，因此，通过 FIFO 不相关的进程也能交换数据。 

3. **信号**

   信号是 Linux 进程间通信的最古老的方式之一，是事件发生时对进程的通知机制，有时也称之为软件中断，它是在软件层次上对中断机制的一种模拟，是一种异步通信的方式。信号可以导致一个正在运行的进程被另一个正在运行的异步进程中断，转而处理某一个突发事件。 

4. **消息队列**

   消息队列就是一个消息的链表，可以把消息看作一个记录，具有特定的格式以及特定的优先级，对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程则可以从消息队列中读走消息，消息队列是随内核持续的。 

5. **共享内存**

   共享内存允许两个或者多个进程共享物理内存的同一块区域（通常被称为段）。由于一个共享内存段会称为一个进程用户空间的一部分，因此这种 IPC 机制无需内核介入。所有需要做的就是让一个进程将数据复制进共享内存中，并且这部分数据会对其他所有共享同一个段的进程可用。与管道等要求发送进程将数据从用户空间的缓冲区复制进内核内存和接收进程将数据从内核内存复制进用户空间的缓冲区的做法相比，这种 IPC 技术的速度更快。 

6. **内存映射**

   内存映射（Memory-mapped I/O）是将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。 

7. **信号量**

   信号量主要用来解决进程和线程间并发执行时的同步问题，进程同步是并发进程为了完成共同任务采用某个条件来协调它们的活动。对信号量的操作分为 P 操作和 V 操作，P 操作是将信号量的值减 1，V 操作是将信号量的值加 1。当信号量的值小于等于 0 之后，再进行 P 操作时，当前进程或线程会被阻塞，直到另一个进程或线程执行了 V 操作将信号量的值增加到大于 0 之时。 

8. **Socket 套接字（Socket）**

   就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。Socket 一般用于网络中不同主机上的进程之间的通信。

## 说一说进程有多少种状态，如何转换

- **创建**：一个进程启动，首先进入创建状态，需要获取系统资源创建进程管理块（PCB：Process Control Block）完成资源分配。
- **就绪**：在创建状态完成之后，进程已经准备好，处于就绪状态，但是还未获得处理器资源，无法运行。
- **运行**：获取处理器资源，被系统调度，当具有时间片开始进入运行状态。如果进程的时间片用完了就进入就绪状态。
- **阻塞**：在运行状态期间，如果进行了阻塞的操作，此时进程暂时无法操作就进入到了阻塞状态，在这些操作完成后就进入就绪状态。等待再次获取处理器资源，被系统调度，当具有时间片就进入运行状态。
- **终止**：进程结束或者被系统终止，进入终止状态。

![img](https://uploadfiles.nowcoder.com/images/20220226/4107856_1645862582392/F6064DA9135BF1E3625665967DCB7E90)

## 请你说说线程的通信方式

线程间无需特别的手段进行通信，因为线程间可以共享一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段等，所以线程之间可以方便、快速地共享信息。只需要将数据复制到共享（全局或堆）变量中即可。

不过，要考虑线程的同步和互斥，应用到的技术有： 

1. **信号**

   Linux 中使用 `pthread_kill()` 函数对线程发信号。 

2. **互斥锁、读写锁、自旋锁**

   互斥锁确保同一时间只能有一个线程访问共享资源，当锁被占用时试图对其加锁的线程都进入阻塞状态（释放 CPU 资源使其由运行状态进入等待状态），当锁释放时哪个等待线程能获得该锁取决于内核的调度。 

   读写锁当以写模式加锁而处于写状态时任何试图加锁的线程（不论是读或写）都阻塞，当以读状态模式加锁而处于读状态时“读”线程不阻塞，“写”线程阻塞。读模式共享，写模式互斥。 

   自旋锁上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对 CPU 的霸占会导致 CPU 资源的浪费。 所以自旋锁适用于并行结构（多个处理器）或者适用于锁被持有时间短而不希望在线程切换产生开销的情况。 

3. **条件变量**

   条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的，条件变量始终与互斥锁一起使用。 

4. **信号量**

   信号量实际上是一个非负的整数计数器，用来实现对公共资源的控制。在公共资源增加的时候，信号量就增加；公共资源减少的时候，信号量就减少；只有当信号量的值大于0的时候，才能访问信号量所代表的公共资源。

## 请你说说进程和线程的区别

1. 进程有独立的地址空间，线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，线程所使用的资源来自其所属进程的资源，线程组之间只能共享资源； 
2. 一个线程属于一个进程，一个进程可以有多个线程
3. 进程和线程切换时，需要切换进程和线程的上下文，进程的上下文切换时间开销远远大于线程上下文切换时间，耗费资源较大，效率要差一些； 
4. 进程的并发性较低，线程的并发性较高； 
5. 每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制； 
6. 一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

## 请你说说线程和协程的区别

1. 线程是操作系统的资源，线程的创建、切换、停止等都非常消耗资源，而创建协程不需要调用操作系统的功能，编程语言自身就能完成，所以协程也被称为用户态线程，协程比线程轻量很多；  

2. 线程在多核环境下是能做到真正意义上的并行，而协程是为并发而产生的； 

3. 一个具有多个线程的程序可以同时运行几个线程，而协程却需要彼此协作的运行； 

4. 线程进程都是同步机制，而协程则是异步； 

5. 线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力； 

6. 操作系统对于线程开辟数量限制在千的级别，而协程可以达到上万的级别。 

## 请你介绍一下死锁，产生的必要条件，产生的原因，怎么预防死锁

1. **死锁**

   两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。这些永远在互相等待的进程称为死锁进程。 

2. **产生死锁的必要条件**

   虽然进程在运行过程中，可能发生死锁，但死锁的发生也必须具备一定的条件，死锁的发生必须具备以下四个必要条件

   - **互斥条件**：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放；
   - **请求和保持条件**：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放；
   - **不剥夺条件**：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放；
   - **环路等待条件**：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合 {P0，P1，P2，···，Pn} 中的 P0 正在等待一个 P1 占用的资源；P1 正在等待 P2 占用的资源，……，Pn 正在等待已被 P0 占用的资源。 

3. **产生死锁的原因**

   竞争资源、进程间推进顺序非法 

4. **预防死锁** 

   有序资源分配法（按顺序上锁）、银行家算法等

- - 

## 请你说说写时拷贝

写时拷贝顾名思义就是“写的时候才分配内存空间”，这实际上是一种拖延战术。

传统的 fork() 系统调用直接把所有的资源复制给新创建的进程，这种实现过于简单并且效率低下，因为它拷贝的数据或许可以共享，或者有时候 fork() 创建新的子进程后，子进程往往要调用一种 exec 函数以执行另一个程序。而 exec 函数会用磁盘上的一个新程序替换当前子进程的正文段、数据段、堆段和栈段，如果之前 fork() 时拷贝了内存，则这时被替换了，这是没有意义的。

Linux 的 fork() 使用写时拷贝（Copy-on-write）页实现。写时拷贝是一种可以推迟甚至避免拷贝数据的技术。内核此时并不复制整个进程的地址空间，而是让父子进程共享同一个地址空间。只用在需要写入的时候才会复制地址空间，从而使各个进行拥有各自的地址空间。也就是说，资源的复制是在需要写入的时候才会进行，在此之前，只有以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候，大大提高了效率。

## 请你说说分段和分页

1. 分段

将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，实现了离散分配。分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

2. 分页

用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。分页主要用于实现虚拟内存，从而获得更大的地址空间。

3. 段页式

页式存储管理能有效地提高内存利用率（解决内存碎片），而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，就形成了段页式存储管理方式。

段页式存储管理方式即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。在段页式系统中，为了实现从逻辑地址到物理地址的转换，系统中需要同时配置段表和页表，利用段表和页表进行从用户地址空间到物理内存空间的映射。

系统为每一个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。在进行地址转换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最终形成物理地址。 

![img](https://uploadfiles.nowcoder.com/images/20220226/4107856_1645862803880/6C835179DEB92D91D06C466A5AD6CCD2)

## 请你说说互斥锁和自旋锁

**互斥锁**：

互斥锁也称为互斥量（Mutex），是一种用来保护临界区的特殊变量， 它可以处于锁定（locked） 状态， 也可以处于解锁（unlocked） 状态： 

如果互斥锁是锁定的， 就是某个特定的线程正持有这个互斥锁；如果没有线程持有这个互斥锁，那么这个互斥锁就处于解锁状态 。每个互斥锁内部有一个线程等待队列，用来保存等待该互斥锁的线程。

当互斥锁处于解锁状态时， 如果某个线程试图获取这个互斥锁， 那么这个线程就可以得到这个互斥锁而不会阻塞；当互斥锁处于锁定状态时， 如果某个线程试图获取这个互斥锁， 那么这个线程将阻塞在互斥锁的等待队列内。 

**自旋锁**：

自旋锁与互斥锁类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可以用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。 自旋锁最多只能被一个可执行线程持有，如果一个执行线程试图获得一个已经被持有的自旋锁，那么该线程就会一直进行忙循环 - 旋转 - 等待锁重新可用。

## 请你说说共享内存

- **原理**

  共享内存是进程间通信的一种方式。不同进程之间共享的内存通常为同一段物理内存，进程可以将同一段物理内存连接到他们自己的地址空间中，所有的进程都可以访问共享内存中的地址。如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。 

- **优点**

  因为所有进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。访问共享内存区域和访问进程独有的内存区域一样快，并不需要通过系统调用或者其它需要切入内核的过程来完成。同时它也避免了对数据的各种不必要的复制。 

- **缺点**

  共享内存没有提供同步机制，这使得我们在使用共享内存进行进程之间的通信时，往往需要借助其他手段来保证进程之间的同步工作。 

## 请你说一说虚拟内存与物理内存

**物理内存**：

以前，还没有虚拟内存概念的时候，程序寻址用的都是物理地址。程序能寻址的范围是有限的，这取决于 CPU 的地址线条数。比如在 32 位平台下，寻址的范围是 2^32 也就是 4G。并且这是固定的，如果没有虚拟内存，且每次开启一个进程都给 4G 物理内存，就可能会出现很多问题，例如： 

1. 因为物理内存是有限的，当有多个进程要执行的时候，都要给 4G 内存，很显然内存不够，这很快就分配完了，于是没有得到分配资源的进程就只能等待。当一个进程执行完了以后，再将等待的进程装入内存。这种频繁的装入内存的操作效率很低
2. 由于指令都是直接访问物理内存的，那么任何进程都可以修改其他进程的数据，甚至会修改内核地址空间的数据，这是不安全的。

**虚拟内存**：

由于物理内存有很多问题，所以出现了虚拟内存。虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

## 请你说说条件变量

条件变量是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待“条件变量的条件成立”而挂起；另一个线程使“条件成立”（给出条件成立信号）。

为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。 使用条件变量可以以原子方式阻塞线程，直到某个特定条件为真为止。条件变量始终与互斥锁一起使用，对条件的测试是在互斥锁（互斥）的保护下进行的。如果条件为假，线程通常会基于条件变量阻塞，并以原子方式释放等待条件变化的互斥锁。如果另一个线程更改了条件，该线程可能会向相关的条件变量发出信号，从而使一个或多个等待的线程执行以下操作：唤醒、再次获取互斥锁、重新评估条件

# Linux 网络编程

## 说一说 select 的原理以及缺点

**select 的原理：**

select 是 一种 IO 多路复用技术，它的主旨思想是： 

1. 首先要构造 3 个（读、写、异常）关于文件描述符的列表，将要监听的文件描述符添加到该列表中，这个文件描述符的列表数据类型为 fd_set，它是一个整型数组，总共是 1024 个比特位，每一个比特位代表一个文件描述符的状态。比如当需要 select 检测时，这一位为 0 就表示不检测对应的文件描述符的事件，为 1 表示检测对应的文件描述符的事件。 
2. 调用 select() 系统调用，监听该列表中的文件描述符的事件，这个函数是阻塞的，直到这些描述符中的一个或者多个进行 I/O 操作时，该函数才返回，并修改文件描述符的列表中对应的值，0 表示没有检测到该事件，1 表示检测到该事件。函数对文件描述符的检测的操作是由内核完成的。 
3. select() 返回时，会告诉进程有多少描述符要进行 I/O 操作，接下来遍历文件描述符的列表进行 I/O 操作。 

**select 的缺点：** 

1. 每次调用select，都必须经历两次拷贝，一次是用户在编写程序时把要检测的 fd 集合拷贝给一个临时变量供系统修改，一次是系统把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大； 
2. 同时每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大； 
3. select 支持的文件描述符数量太小了，默认是 1024（由 fd_set 决定）； 
4. 每次 select 返回后，只能知道有几个 fd 发生了事件，但是具体哪几个还需要遍历文件描述符集合进一步判断。

## 说一说 epoll 的原理

**epoll 的使用步骤及原理：** 

1. 调用 epoll_create() 会在内核中创建一个 eventpoll 结构体数据，称之为 epoll 对象，在这个结构体中有 2 个比较重要的数据成员，一个是需要检测的文件描述符的信息 struct_root rbr（红黑树），还有一个是就绪列表struct list_head rdlist，存放检测到数据发生改变的文件描述符信息（双向链表）； 

2. 调用 epoll_ctrl() 可以向 epoll 对象中添加、删除、修改要监听的文件描述符及事件； 

3. 调用 epoll_wait() 可以让内核去检测就绪的事件，并将就绪的事件放到就绪列表中并返回，通过返回的事件数组做进一步的事件处理。

**epoll 的两种工作模式：**  

1. LT 模式（水平触发） LT（Level - Triggered）是缺省的工作方式，并且同时支持阻塞和非阻塞 socket。在这种做法中，内核检测到一个文件描述符就绪了，然后可以对这个就绪的 fd 进行 IO 操作，如果不作任何操作，内核还是会继续通知。 

2. ET 模式（边沿触发） ET（Edge - Triggered）是高速工作方式，只支持非阻塞 socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 检测到。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个 fd 进行 IO 操作（从而导致它再次变成未就绪），内核不会发送更多的通知（only once）。 ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll 工作在 ET 模式的时候，必须使用非阻塞 socket，以避免由于一个文件描述符的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 

## 请你介绍一下 I/O 多路复用

I/O 多路复用是一种使得程序能同时监听多个文件描述符的技术，从而提高程序的性能。I/O 多路复用能够在单个线程中，通过监视多个 I/O 流的状态来同时管理多个 I/O 流，一旦检测到某个文件描述符上我们关心的事件发生（就绪），能够通知程序进行相应的处理（读写操作）。 Linux 下实现 I/O 复用的系统调用主要有 select、poll 和 epoll。

- **select**
  - 略
- **poll**
  - poll 的原理和 select 类似，但只需要传入一个文件描述符集合，形式是链表，因此数量没有限制。
  - 集合中的每个元素是结构体，`events`（感兴趣的事件） 和 `revents`（实际发生的事件） 字段让程序更加清晰地了解事件状态，不像 `select` 需要手动检查哪些文件描述符可用，因此更加直观。
- **epoll**
  - 略



# 计算机网络

## 请你说说 TCP 和 UDP 的区别

**相同点**：

UDP 协议和 TCP 协议都是运输层协议，都是为应用层程序服务，都具有复用（不同的应用层协议可以共用 UDP 协议和 TCP 协议）和分用（将数据报解析之后分发给不同的应用层程序）的功能。

**不同点**：

| UDP                                                          | TCP                                                          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 面向无连接（不需要三次握手和四次挥手）                       | 面向连接（需要三次握手四次挥手）                             |
| 尽最大努力交付                                               | 可靠交付（有大量的机制保护TCP连接数据的可靠性）              |
| 面向报文（每次收发都是一整个报文段）                         | 面向字节流（不保留数据报边界的情况下以字节流的方式进行传输，这也是长连接的由来。） |
| 没有拥塞控制，不可靠（只管发不管过程和结果）                 | 有拥塞控制机制                                               |
| 支持一对一、一对多、多对一和多对多的通信方式                 | 单播（只能端对端的连接），全双工通讯（允许双方同时发送信息，也是四次挥手的原由） |
| 首部开销很小（8字节）                                        | 头部开销大（最少20字节）                                     |
| 优点是快，没有TCP各种机制，少了很多首部信息和重复确认的过程，节省了大量的网络资源 | 缺点是慢，效率低，占用系统资源高，在传递数据之前要先建立连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接。 |
| 缺点是不可靠不稳定，只管数据的发送不管过程和结果，网络不好的时候很容易造成数据丢失 | 优点是可靠、稳定，有确认、窗口、重传、拥塞控制机制，在数据传完之后，还会断开连接用来节约系统资源。 |
| 应用：网络不好的时候不会影响到主机数据报的发送速率，这对很多实时的应用程序很重要，因为像语音通话、视频会议等要求源主机要以恒定的速率发送数据报，允许网络不好的时候丢失一些数据，但不允许太大的延迟，UDP很适合这种要求。 | 应用：在要求数据准确、对速度没有硬性要求的场景有很好的表现，比如在FTP（文件传输）、HTTP/HTTPS（超文本传输），TCP很适合这种要求。 |

## 请你说说 TCP 三次握手四次挥手过程

> 握手：SYN，SYN ACK，ACK
>
> 挥手：FIN，ACK，FIN，ACK

**三次握手过程**：

1. 客户端向服务器端发送连接请求报文段，包含自身数据通讯初始序号，进入 SYN-SENT 状态。
2. 服务器端收到连接请求报文段后，如果同意，发送应答，包含自身数据通讯初始序号，进入 SYN-RECEIVED 状态。
3. 客户端收到应答，最后向服务器端发送确认报文，进入 ESTABLISHED 状态，此时成功建立长连接。  

![理论经典：TCP协议的3次握手与4次挥手过程详解_2.png](http://www.52im.net/data/attachment/forum/201604/26/141753hc3p885th8e6z55n.png)

**四次挥手过程**：

1. 客户端认为数据发送完毕，需要向服务器端发送连接释放请求。
2. 服务器收到连接释放请求，告诉应用层释放TCP连接。然后发送ACK包，进入CLOSE-WT状态，此时表明客户端到服务器端的连接已经释放，不再接受客户端的数据。因为TCP是全双工的，所以服务器仍可以发送数据。
3. 当服务器端数据发送完毕，向客户端发送连接释放请求，进入LAST-ACK状态。
4. 客户端收到连接释放请求，向服务器端发送确认应答报文，此时客户端进入TIME-WT状态，持续2倍的MSL（最长报文段寿命），若期间没有收到服务器端的数据报文，进入CLOSED状态。服务器端收到确认应答后，也进入CLOSED状态。  

![理论经典：TCP协议的3次握手与4次挥手过程详解_3.png](http://www.52im.net/data/attachment/forum/201604/26/142520px6qkzx886895jn8.png)

## 请你说说 OSI 七层模型

OSI（Open System Interconnection） 七层模型是一个协议栈，就是为了统一计算机网络标准，方便数据的交换。它自上而下依次为：

1. 应用层，应用层是体系结构中的最高层，是应用进程间通信和交互的规则，进程指计算机中运行的程序。也是用户与应用程序之间的一个接口，操作程序（软件，Web应用），进而触发更下层的服务。 协议：HTTP、HTTPS、FTP、TFTP、SMTP等
2. 表示层，对从应用层获取到的数据报文数据进行格式处理、安全处理和压缩处理。 格式：JPEG、ASCll、加密格式等
3. 会话层，对当前主机进程和目标主机进程会话的建立、管理和终止行为。
4. 传输层，对两台主机进程也就是应用层提供数据传输服务。定义了传输数据的进程端口号，负责数据包的排序、差错检验和流量控制等。 协议：UDP、TCP
5. 网络层，主要进行逻辑地址的查询。 协议： ICMP、IGMP、IP（IPv4、IPv6）
6. 数据链路层，建立相邻节点的逻辑连接，进行逻辑地址寻址、差错校验等。 协议：ARP、RARP、PPP 等
7. 物理层，物理层上数据的单位是Bit比特，数据的传输都是通过0（或1）比特流来实现的，而0（或1）比特流与电压的高低有关。负责了最底层数据传输的建立、传输和断开。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/02086911423c8c80b7566b9c1f668eba.png#pic_center)

## 请你说说 TCP/IP 五层模型

1. **应用层**：应用层是体系结构中的最高层，定义了应用进程间通信和交互的规则。本层任务就是通过应用进程间的信息数据流通完成特定的网络应用（软件、Web应用等）。因为不同的应用程序都需要不同的应用层协议，所以应用层协议较多，如万维网应用的HTTP协议、电子邮件的SMTP协议、文件传送的DTP协议等。请将应用层交互的数据称为报文，以免产生概念的混淆。 协议：HTTP、HTTPS、FTP、TFTP、SMTP等
2. **传输层**：运输层的任务是负责向两个计算机中进程之间的通信提供一种通用的数据传输服务，应用层通过运输层可以传输报文。通用是指不会针对特定的应用层协议进行详细的划分，多种应用层协议公用同一个运输层服务，所以运输层有复用的功能。当然也有分发的功能，指将接受到的信息分别交付到应用层不同的进程中。 协议：UDP、TCP
3. **网络层**：网络层的任务是负责为网络上不同的主机提供通信服务。在发送数据时，网络层将运输层产生的报文段或者用户数据报封装成分组或者包（packet）进行传送。由于网络层使用IP协议，所以分组或包（packet）也叫IP数据报，简称数据报。网络层还需要寻找合适的路由路线，让源主机运输层发送下来的数据报能通过路由器找到目的主机。 协议：ICMP、IGMP、IP（IPv4、IPv6）、
4. **数据链路层**：数据链路层简称链路层。两个节点传输数据时，链路层将网络层交下来的数据报组装成帧，在链路上传送帧。每一帧都包括数据和控制信息（同步信息、地址信息、差错控制等）。协议：ARP、RARP
5. **物理层**：物理层上数据的单位是Bit比特，数据的传输都是通过0（或1）比特流来实现的，而0（或1）比特流与电压的高低有关。物理层中比特流的传输不再加控制信息，需要注意的是比特流应从首部开始传送。

## 请你说说 TCP 如何实现可靠传输

可靠传输就是通过TCP连接传送的数据是没有差错、不会丢失、不重复并且按序到达的。TCP是通过序列号、检验和、确认应答信号、重发机制、连接管理、流量控制、拥塞控制等一起保证TCP传输的可靠性的。

- **连接管理**：三次握手四次挥手
- **序列号**：TCP给发送的每一个包都进行编号，接收方对数据包进行排序，把有序数据传送给应用层，TCP的接收端会丢弃重复的数据。 
- **停止等待协议**：它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。  
- **检验和**：TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。
- **确认应答**：如果收到的数据报报文段的检验和没有差错，就确认收到，如果有差错，TCP就丢弃这个报文段和不确认收到此报文段。 
- **超时重传**： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
- **流量控制**：TCP 连接的每一方都有固定大小的缓冲空间，TCP的发送端只能发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。  
- **拥塞控制**：当网络拥塞时，减少数据的发送。 